{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "L4",
      "authorship_tag": "ABX9TyNKO6oPA8i3aRwbR8zFXObg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Max-JI64/Kakao_Tech_Bootcamp/blob/main/Assignment/week7/7%EC%A3%BC%EC%B0%A8%EA%B3%BC%EC%A0%9C1_max_ji.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 사전 훈련된 ResNet-18"
      ],
      "metadata": {
        "id": "gcoG1QMGIVpF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "허깅페이스에서 불러온다"
      ],
      "metadata": {
        "id": "2w77GQ5GJSYp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "\n",
        "#예시 이미지넷 고양이 데이터\n",
        "dataset = load_dataset(\"huggingface/cats-image\")\n",
        "image = dataset[\"test\"][\"image\"][0]\n",
        "\n",
        "#이미지 전처리기 및 모델 불러오기\n",
        "image_processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-18\")\n",
        "model = AutoModelForImageClassification.from_pretrained(\"microsoft/resnet-18\")\n",
        "\n",
        "#이미지 전처리\n",
        "inputs = image_processor(image, return_tensors=\"pt\")\n",
        "\n",
        "#예측\n",
        "with torch.no_grad():\n",
        "    logits = model(**inputs).logits\n",
        "\n",
        "# model predicts one of the 1000 ImageNet classes\n",
        "predicted_label = logits.argmax(-1).item()\n",
        "print(model.config.id2label[predicted_label])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375,
          "referenced_widgets": [
            "bc54dfbb98d14ee3bfa26c3979c579b7",
            "3a19794e4a084adebf817353d7c10aee",
            "d5947363c0d64a4293c741696b47b28b",
            "eb1e1405f5c043309564535c937673b2",
            "b35d5e91e0d2456c94e6dbb8869dd406",
            "11550a4b399f4ecfaeebdc053a4d426c",
            "6878a0b1b099401f8f4f0276752d80c9",
            "2209c836668748ee8921d5764c9d10d0",
            "09afefbdd7994b5f8e556c9b669c60ec",
            "1e89984ebd22484a90624f2a643bae68",
            "7cd37dea5b8f449c88c632c457e59a89",
            "c792d71a3a9d4ffeaa600c38d4aa4681",
            "e4c9f200cee74239b141cd70a617d179",
            "ac4a7cf4f96c48fba014f1237c1620f5",
            "831219a97cf24ebca2cd354d94123787",
            "a5a590178dc84f918504e82d70b3b285",
            "edc88330f44f490e90621787edc9f617",
            "fd0bb7a6eeb2413087b9f5ae3da5601e",
            "8d6721282fe940f7a2312dd3903f7233",
            "c7f3a3824a4b4a78bff6b1d57ccc11bd",
            "1fb170bf68954b2ea9935fd753d09594",
            "73922fcb3150412ba3c447b51833be4c",
            "3a6a83c3d802496b8af665af68fb3074",
            "2282f95df24944fabbb826d6d5e63b50",
            "38cafa52c32240b6b84fa08d6614e1af",
            "28f69385ec564819b6e195d6a333e981",
            "307b70a5e14d4640a51c7793bba651e9",
            "c71d2cf8bf8a451a9c613d4b112d1caf",
            "7a177971f78a4fba9c09f1c2352e7362",
            "82b1128b1e7c4bd69c637de6c9722430",
            "104e1738f2b0466ea68ef1e88220caea",
            "63f85312bb97447b828a4a08caf64a28",
            "f3c173664f6e4099a28a9dfcbdf6ebb5",
            "294921eb4033470d95e12a6ceee7350b",
            "7c79055f45524a39b823f4942b2b21f5",
            "98da6df4513843adafcb0f1020179816",
            "7337f2857e924c9f8882b3ffe6a480b1",
            "e1312d6858404f1c81fda202e6a1c53e",
            "918c97017dc240d9bf1ccfad762f098a",
            "d814e293bfc9468d937a6733252a2b38",
            "5dd41d999f444617965a7258c60c6826",
            "f22c58dd33b548e388118cb4dd609824",
            "900bd2a8794d4e6993a41e8dd8602a28",
            "bbe3bd955573466f8cce0b1239841828",
            "69e1fae09e3a4da2b057758d75e9c2ae",
            "6d3c562d9a714bec8167e371053c183b",
            "9d4ec1782d0d4d5ca1289dce013f9811",
            "f043304fd4834712b60585ba6333a023",
            "6d03b3085ed84923b1d4233f682f02f2",
            "5e2d2f744fe849e2bdbcd68557628f0e",
            "ead5d536f5e64327b02e03e3643e2814",
            "60deca5ce1754516ab72766d65ed8341",
            "668e0ef0692d403f9daffe9a82d04845",
            "12940cb440b5404f8a4b30a7f6be2386",
            "eec59cd942c44300864b57710ecb1aeb",
            "d285fdd96cd143628679d5c1edc2fecb",
            "0fa5e9bf05634629a155c5cb059671fb",
            "d77233da9dab4fdfad429ae9d540e17e",
            "4cbb02fe1c1944478a024824df628b1b",
            "17ab150db08d41f289a23453659348f1",
            "ac63894b4ab54c6b87495a4e42ae2cc7",
            "58a1b44cf3074205877b87e4c886b36b",
            "6069f135c6864a8cb2dee631bc7feedd",
            "1f8d822d4fb741b0907129bd6e76cf09",
            "21ed0d05c8d54bab861b6cc4c4ae57ee",
            "d86df9ebf97c487ca39329f51a8bef47"
          ]
        },
        "id": "DGobKIiXI5Og",
        "outputId": "ce8b12a6-5fa6-43a8-b7cf-05aff4e98ca7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/96.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc54dfbb98d14ee3bfa26c3979c579b7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "cats_image.jpeg:   0%|          | 0.00/173k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c792d71a3a9d4ffeaa600c38d4aa4681"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/1 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a6a83c3d802496b8af665af68fb3074"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/266 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "294921eb4033470d95e12a6ceee7350b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "69e1fae09e3a4da2b057758d75e9c2ae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/46.8M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d285fdd96cd143628679d5c1edc2fecb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tabby, tabby cat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koi0hAipNXPc",
        "outputId": "52e4e270-81cc-4934-da99-f2371a483267"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNetForImageClassification(\n",
            "  (resnet): ResNetModel(\n",
            "    (embedder): ResNetEmbeddings(\n",
            "      (embedder): ResNetConvLayer(\n",
            "        (convolution): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "        (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (activation): ReLU()\n",
            "      )\n",
            "      (pooler): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "    )\n",
            "    (encoder): ResNetEncoder(\n",
            "      (stages): ModuleList(\n",
            "        (0): ResNetStage(\n",
            "          (layers): Sequential(\n",
            "            (0): ResNetBasicLayer(\n",
            "              (shortcut): Identity()\n",
            "              (layer): Sequential(\n",
            "                (0): ResNetConvLayer(\n",
            "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (activation): ReLU()\n",
            "                )\n",
            "                (1): ResNetConvLayer(\n",
            "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (activation): Identity()\n",
            "                )\n",
            "              )\n",
            "              (activation): ReLU()\n",
            "            )\n",
            "            (1): ResNetBasicLayer(\n",
            "              (shortcut): Identity()\n",
            "              (layer): Sequential(\n",
            "                (0): ResNetConvLayer(\n",
            "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (activation): ReLU()\n",
            "                )\n",
            "                (1): ResNetConvLayer(\n",
            "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (activation): Identity()\n",
            "                )\n",
            "              )\n",
            "              (activation): ReLU()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (1): ResNetStage(\n",
            "          (layers): Sequential(\n",
            "            (0): ResNetBasicLayer(\n",
            "              (shortcut): ResNetShortCut(\n",
            "                (convolution): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "              (layer): Sequential(\n",
            "                (0): ResNetConvLayer(\n",
            "                  (convolution): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (activation): ReLU()\n",
            "                )\n",
            "                (1): ResNetConvLayer(\n",
            "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (activation): Identity()\n",
            "                )\n",
            "              )\n",
            "              (activation): ReLU()\n",
            "            )\n",
            "            (1): ResNetBasicLayer(\n",
            "              (shortcut): Identity()\n",
            "              (layer): Sequential(\n",
            "                (0): ResNetConvLayer(\n",
            "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (activation): ReLU()\n",
            "                )\n",
            "                (1): ResNetConvLayer(\n",
            "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (activation): Identity()\n",
            "                )\n",
            "              )\n",
            "              (activation): ReLU()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (2): ResNetStage(\n",
            "          (layers): Sequential(\n",
            "            (0): ResNetBasicLayer(\n",
            "              (shortcut): ResNetShortCut(\n",
            "                (convolution): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "              (layer): Sequential(\n",
            "                (0): ResNetConvLayer(\n",
            "                  (convolution): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (activation): ReLU()\n",
            "                )\n",
            "                (1): ResNetConvLayer(\n",
            "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (activation): Identity()\n",
            "                )\n",
            "              )\n",
            "              (activation): ReLU()\n",
            "            )\n",
            "            (1): ResNetBasicLayer(\n",
            "              (shortcut): Identity()\n",
            "              (layer): Sequential(\n",
            "                (0): ResNetConvLayer(\n",
            "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (activation): ReLU()\n",
            "                )\n",
            "                (1): ResNetConvLayer(\n",
            "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (activation): Identity()\n",
            "                )\n",
            "              )\n",
            "              (activation): ReLU()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (3): ResNetStage(\n",
            "          (layers): Sequential(\n",
            "            (0): ResNetBasicLayer(\n",
            "              (shortcut): ResNetShortCut(\n",
            "                (convolution): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "              )\n",
            "              (layer): Sequential(\n",
            "                (0): ResNetConvLayer(\n",
            "                  (convolution): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (activation): ReLU()\n",
            "                )\n",
            "                (1): ResNetConvLayer(\n",
            "                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (activation): Identity()\n",
            "                )\n",
            "              )\n",
            "              (activation): ReLU()\n",
            "            )\n",
            "            (1): ResNetBasicLayer(\n",
            "              (shortcut): Identity()\n",
            "              (layer): Sequential(\n",
            "                (0): ResNetConvLayer(\n",
            "                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (activation): ReLU()\n",
            "                )\n",
            "                (1): ResNetConvLayer(\n",
            "                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "                  (activation): Identity()\n",
            "                )\n",
            "              )\n",
            "              (activation): ReLU()\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Flatten(start_dim=1, end_dim=-1)\n",
            "    (1): Linear(in_features=512, out_features=1000, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CIFAR-10 데이터셋"
      ],
      "metadata": {
        "id": "5cLy2VUPIYSL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch로 CIFAR-10 불러오기"
      ],
      "metadata": {
        "id": "7XYljk8cJ3_8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이때 ResNet-18은 224x224로 학습이 된 모델이고,   \n",
        "CIFAR-10은 32x32크기이다  \n",
        "\n",
        "따라서 CIFAR-10의 크기를 ResNet-18에 맞게 변환시켜야 한다"
      ],
      "metadata": {
        "id": "aa7pW3obLE3c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoImageProcessor\n",
        "\n",
        "#ResNet-18 전처리기\n",
        "processor = AutoImageProcessor.from_pretrained(\"microsoft/resnet-18\")\n",
        "#정규화 값\n",
        "imagenet_mean = processor.image_mean\n",
        "imagenet_std  = processor.image_std\n",
        "\n",
        "#이미지 전처리\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(256), #이미지를 256x256으로 변환\n",
        "    transforms.CenterCrop(224), #이미지를 중앙에서 224x224로 자름\n",
        "    transforms.ToTensor(), #이미지를 텐서로 변환\n",
        "    # CIFAR-10을 [0,1] 정규화\n",
        "    transforms.Normalize(mean=imagenet_mean, std=imagenet_std)\n",
        "])\n",
        "\n",
        "#train 데이터셋 다운로드\n",
        "train_dataset = datasets.CIFAR10(\n",
        "    root='./data', #다운로드 경로\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=transform # 전처리 함수 적용\n",
        ")\n",
        "\n",
        "#test 데이터셋 다운로드\n",
        "test_dataset = datasets.CIFAR10(\n",
        "    root='./data',\n",
        "    train=False, #test dataset\n",
        "    download=True,\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "#안정적인 학습을 위해 배치 사이즈 설정 및 셔플\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "59ZcClx6J7TF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"훈련 데이터셋 크기: {len(train_dataset)}\")\n",
        "print(f\"테스트 데이터셋 크기: {len(test_dataset)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3RxNWa8KkSp",
        "outputId": "fe4fa46f-e26b-458a-f156-a7bc4713043d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "훈련 데이터셋 크기: 50000\n",
            "테스트 데이터셋 크기: 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 학습 없이 바로 inference(추론)"
      ],
      "metadata": {
        "id": "H095xbZNIdJM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet-18 새로 불러오기 및 평가 모드 전환"
      ],
      "metadata": {
        "id": "Rws9TAPhPJY_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModelForImageClassification\n",
        "\n",
        "#GPU 사용\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "#ResNet-18 불러오기\n",
        "model = AutoModelForImageClassification.from_pretrained(\"microsoft/resnet-18\")\n",
        "\n",
        "#분류 레드를 CIFAR-10에 맞게 10개의 클래스 분류로 수정\n",
        "out_feats = model.config.hidden_sizes[-1]  # 보통 512\n",
        "model.classifier = nn.Sequential(\n",
        "    nn.Flatten(start_dim=1),\n",
        "    nn.Linear(out_feats, 10)\n",
        ")\n",
        "\n",
        "model.to(device)\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9arHbmmOkg3",
        "outputId": "e978c5e1-c2d9-4385-8300-875cb8d85319"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNetForImageClassification(\n",
              "  (resnet): ResNetModel(\n",
              "    (embedder): ResNetEmbeddings(\n",
              "      (embedder): ResNetConvLayer(\n",
              "        (convolution): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "        (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (pooler): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (encoder): ResNetEncoder(\n",
              "      (stages): ModuleList(\n",
              "        (0): ResNetStage(\n",
              "          (layers): Sequential(\n",
              "            (0): ResNetBasicLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1): ResNetBasicLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1): ResNetStage(\n",
              "          (layers): Sequential(\n",
              "            (0): ResNetBasicLayer(\n",
              "              (shortcut): ResNetShortCut(\n",
              "                (convolution): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1): ResNetBasicLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): ResNetStage(\n",
              "          (layers): Sequential(\n",
              "            (0): ResNetBasicLayer(\n",
              "              (shortcut): ResNetShortCut(\n",
              "                (convolution): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1): ResNetBasicLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (3): ResNetStage(\n",
              "          (layers): Sequential(\n",
              "            (0): ResNetBasicLayer(\n",
              "              (shortcut): ResNetShortCut(\n",
              "                (convolution): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1): ResNetBasicLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "예측 및 정확도 계산"
      ],
      "metadata": {
        "id": "4iALUcIGPQjG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "total, correct = 0, 0\n",
        "\n",
        "with torch.no_grad(): #그레디언트 계산 사용하지 않음 <- 학습을 하지 않기 때문에\n",
        "    for imgs, labels in test_loader: #배치 단위로 예측 진행\n",
        "        imgs, labels = imgs.to(device), labels.to(device) #이미지와 라벨을 device(GPU)로 올림\n",
        "        logits = model(pixel_values=imgs).logits #예측 진행\n",
        "        preds = logits.argmax(1) #가장 큰 점수의 인덱스 - 예측 클래스를 추출\n",
        "\n",
        "        correct += (preds == labels).sum().item() #맞춘 것(예측과 라벨이 동일한것)의 합\n",
        "        total   += labels.size(0) #하나의 배치 사이즈, 64를 의미\n",
        "\n",
        "acc = correct / total * 100\n",
        "print(f\"파인튜닝을 하지 않았을 때 CIFAR-10 테스트 정확도: {acc:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8Wx_49lPUl9",
        "outputId": "7e9d52f2-50b7-45be-c8aa-981da3d8078c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "파인튜닝을 하지 않았을 때 CIFAR-10 테스트 정확도: 8.74%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# I. Full Fine Tuning"
      ],
      "metadata": {
        "id": "KJr6KXALItMG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "기존 모델 전체의 레이어, 파라미터를 학습시킨다"
      ],
      "metadata": {
        "id": "ghOAtAsYd0gD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, random, math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, random_split, Subset\n",
        "from torchvision import datasets, transforms\n",
        "from transformers import AutoImageProcessor\n",
        "import numpy as np\n",
        "\n",
        "# 재현성 고정\n",
        "def set_seed(seed=42):\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)  # multi-GPU 환경\n",
        "    torch.backends.cudnn.deterministic = True  # 완전 재현을 원할 때\n",
        "    torch.backends.cudnn.benchmark = False     # GPU 최적화 탐색 비활성 (불확실성 제거)\n",
        "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
        "    print(f\"[Seed fixed to {seed}]\")"
      ],
      "metadata": {
        "id": "5LQyV_TeXfck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## train데이터셋을 train, validation으로 분리"
      ],
      "metadata": {
        "id": "_7YER0dhXziN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train_dataset))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HVTLaNNgX4Ax",
        "outputId": "2d38b121-18e1-4dc2-e5f0-1899361b5ea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CIFAR-10 라벨 매핑\n",
        "id2label = {i: c for i, c in enumerate(train_dataset.dataset.classes if hasattr(train_dataset, \"dataset\") else train_dataset.classes)}\n",
        "label2id = {v: k for k, v in id2label.items()}\n",
        "id2label\n",
        "\n",
        "#train. validation 분할\n",
        "train_dataset, val_dataset = random_split(train_dataset, [40000, 10000],\n",
        "                                          generator=torch.Generator().manual_seed(42))\n",
        "\n",
        "\n",
        "#데이터 로더 다시 설정\n",
        "train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True,\n",
        "                          num_workers=2, pin_memory=(device.type == \"cuda\"), drop_last=True)\n",
        "val_loader   = DataLoader(val_dataset,   batch_size=128, shuffle=False,\n",
        "                          num_workers=2, pin_memory=(device.type == \"cuda\"))\n",
        "test_loader  = DataLoader(test_dataset,  batch_size=128, shuffle=False,\n",
        "                          num_workers=2, pin_memory=(device.type == \"cuda\"))"
      ],
      "metadata": {
        "id": "cJhT1dWFYCOD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet-18 모델 재로드 및 출력부 헤드 설정"
      ],
      "metadata": {
        "id": "CQafWXjPZKwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4_zzrQS16Ri",
        "outputId": "5a2ddcd3-182b-424a-946c-045fa3f04c1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed fixed to 42]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification\n",
        "\n",
        "num_labels = 10 #CIFAR-10 클래스의 개수\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    \"microsoft/resnet-18\",\n",
        "    num_labels=num_labels,\n",
        "    ignore_mismatched_sizes=True  # 분류기 헤드 차원 재설정 시 편의용\n",
        ")\n",
        "\n",
        "#CIFAR-10 라벨 이름 반영\n",
        "model.config.id2label = id2label\n",
        "model.config.label2id = label2id\n",
        "\n",
        "model.to(device) #GPU로 업로드"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eZiMlxcrZO5I",
        "outputId": "7f53c42e-2690-4859-9ec0-919432d2a7eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-18 and are newly initialized because the shapes did not match:\n",
            "- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([10]) in the model instantiated\n",
            "- classifier.1.weight: found shape torch.Size([1000, 512]) in the checkpoint and torch.Size([10, 512]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNetForImageClassification(\n",
              "  (resnet): ResNetModel(\n",
              "    (embedder): ResNetEmbeddings(\n",
              "      (embedder): ResNetConvLayer(\n",
              "        (convolution): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "        (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (pooler): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (encoder): ResNetEncoder(\n",
              "      (stages): ModuleList(\n",
              "        (0): ResNetStage(\n",
              "          (layers): Sequential(\n",
              "            (0): ResNetBasicLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1): ResNetBasicLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1): ResNetStage(\n",
              "          (layers): Sequential(\n",
              "            (0): ResNetBasicLayer(\n",
              "              (shortcut): ResNetShortCut(\n",
              "                (convolution): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1): ResNetBasicLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): ResNetStage(\n",
              "          (layers): Sequential(\n",
              "            (0): ResNetBasicLayer(\n",
              "              (shortcut): ResNetShortCut(\n",
              "                (convolution): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1): ResNetBasicLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (3): ResNetStage(\n",
              "          (layers): Sequential(\n",
              "            (0): ResNetBasicLayer(\n",
              "              (shortcut): ResNetShortCut(\n",
              "                (convolution): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1): ResNetBasicLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 파라미터 설정, 손실함수, 옵티마이저"
      ],
      "metadata": {
        "id": "Hg0zVSFbZgz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#풀 파인 튜닝 -> 모든 레이어를 학습, 전체 파라미터 업데이트\n",
        "for p in model.parameters():\n",
        "    p.requires_grad = True\n",
        "\n",
        "criterion = nn.CrossEntropyLoss() #크로스엔트로피 손실함수\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01) #Adma 옵티마이저, 학습률 0.0001, 가중치 감쇠 : 0.001 -> 과적합 방지"
      ],
      "metadata": {
        "id": "aDi0nQrTaftl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습"
      ],
      "metadata": {
        "id": "qmUJXOj_avqL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time()  # 학습 시작 시간\n",
        "\n",
        "epochs = 10 #에포크 10\n",
        "\n",
        "for epoch in range(1, epochs + 1): #각 에포크마다 학습 진행\n",
        "    model.train()  #모델 학습모드로 변환\n",
        "    total, correct, loss_sum = 0, 0, 0.0 #train 이미지 수, 맞힌 개수, 손실 누적합\n",
        "    for imgs, labels in train_loader: #각 배치별로\n",
        "        imgs, labels = imgs.to(device), labels.to(device) #데이터를 GPU로 옮김\n",
        "\n",
        "        optimizer.zero_grad() #이전 배치에서의 그레디언트를 초기화\n",
        "        logits = model(pixel_values=imgs).logits #로짓 출력 결과값 얻음\n",
        "        loss = criterion(logits, labels) #손실 계산\n",
        "        loss.backward() #역전파 진행\n",
        "        optimizer.step() #계산된 그레디언트로 모델의 파라미터를 한 스텝 업데이트\n",
        "\n",
        "        loss_sum += loss.item() * labels.size(0) #이번 배치의 손실값을 누적합에 더함, lebels.size(0)는 배치의 크기\n",
        "        correct += (logits.argmax(1) == labels).sum().item() #정답을 맞춘 것의 개수\n",
        "        total += labels.size(0) #처리한 데이터의 개수 (배치 크기)\n",
        "\n",
        "    #평균 손실과 정확도 계산\n",
        "    train_loss = loss_sum / total\n",
        "    train_acc  = correct / total * 100\n",
        "\n",
        "    # validation 평가\n",
        "    # train의 결과 평가와 같은 구조\n",
        "    model.eval() #모델 평가모드로 전환\n",
        "    v_total, v_correct, v_loss_sum = 0, 0, 0.0\n",
        "    with torch.no_grad(): #평가에선 그레디언트를 사용하지 않음\n",
        "        for imgs, labels in val_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            logits = model(pixel_values=imgs).logits\n",
        "\n",
        "            v_loss_sum += criterion(logits, labels).item() * labels.size(0)\n",
        "            v_correct += (logits.argmax(1) == labels).sum().item()\n",
        "            v_total += labels.size(0)\n",
        "\n",
        "    val_loss = v_loss_sum / v_total\n",
        "    val_acc  = v_correct / v_total * 100\n",
        "    #학습, 검증 손실 및 정확도 출력\n",
        "    print(f\"[{epoch}/{epochs}] train_loss {train_loss:.4f} acc {train_acc:.2f}% | val_loss {val_loss:.4f} acc {val_acc:.2f}%\")\n",
        "\n",
        "print(\"-\"*30)\n",
        "total_time = time.time() - start_time\n",
        "print(f\"Full Fine Tuning 학습 소요 시간: {total_time:.2f}초\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTEceZCWaw0v",
        "outputId": "8cabafed-79a6-4219-fc87-2f623d45c345"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/10] train_loss 0.4217 acc 86.09% | val_loss 0.2138 acc 92.86%\n",
            "[2/10] train_loss 0.1107 acc 96.63% | val_loss 0.2023 acc 93.10%\n",
            "[3/10] train_loss 0.0338 acc 99.28% | val_loss 0.1917 acc 93.85%\n",
            "[4/10] train_loss 0.0122 acc 99.83% | val_loss 0.1926 acc 94.16%\n",
            "[5/10] train_loss 0.0049 acc 99.97% | val_loss 0.1780 acc 94.77%\n",
            "[6/10] train_loss 0.0022 acc 100.00% | val_loss 0.1665 acc 95.07%\n",
            "[7/10] train_loss 0.0011 acc 100.00% | val_loss 0.1697 acc 95.10%\n",
            "[8/10] train_loss 0.0009 acc 100.00% | val_loss 0.1734 acc 94.93%\n",
            "[9/10] train_loss 0.0067 acc 99.82% | val_loss 0.5032 acc 88.14%\n",
            "[10/10] train_loss 0.1043 acc 96.36% | val_loss 0.2095 acc 93.52%\n",
            "------------------------------\n",
            "Full Fine Tuning 학습 소요 시간: 714.13초\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 테스트 평가"
      ],
      "metadata": {
        "id": "zOwcsIeOa7dE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#validation의 경우와 같음\n",
        "model.eval()\n",
        "total, correct, loss_sum = 0, 0, 0.0\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in test_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        logits = model(pixel_values=imgs).logits\n",
        "        loss_sum += criterion(logits, labels).item() * labels.size(0)\n",
        "        correct += (logits.argmax(1) == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "test_loss = loss_sum / total\n",
        "test_acc  = correct / total * 100\n",
        "print(\"Full Fine Tuning CIFAR-10 테스트 손실 및 정확도\")\n",
        "print(f\"test_loss {test_loss:.4f} acc {test_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QP_OXRvSa8mo",
        "outputId": "4292c4b7-9061-49f0-912c-d79442848ddc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Full Fine Tuning CIFAR-10 테스트 손실 및 정확도\n",
            "test_loss 0.2336 acc 92.95%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# II. Partial Fine Tuning"
      ],
      "metadata": {
        "id": "ph-Y8mY_d5qJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "기존 모델의 일부 레이어만 학습시킨다  \n",
        "초기층은 그대로 유지,  \n",
        "후반부 블록이나 분류기와 같은 상위 계층만 학습"
      ],
      "metadata": {
        "id": "PxISmjlid8O6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "이를 통해 이미 학습된 엣지, 색상과 같은 저수준의 특징 그대로 활용  \n",
        "학습 속도 빠르고 자원 절약  \n",
        "작은 데이터셋일때 과적합 방지"
      ],
      "metadata": {
        "id": "Af-OGTeveJlg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet-18 모델 재로드 및 출력부 헤드 설정"
      ],
      "metadata": {
        "id": "vnksKVKEfOW2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1A4sBFqa17r5",
        "outputId": "5434da33-06bc-4746-ba1e-828ec8d228d9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed fixed to 42]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification\n",
        "\n",
        "num_labels = 10 #CIFAR-10 클래스의 개수\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    \"microsoft/resnet-18\",\n",
        "    num_labels=num_labels,\n",
        "    ignore_mismatched_sizes=True  # 분류기 헤드 차원 재설정 시 편의용\n",
        ")\n",
        "\n",
        "#CIFAR-10 라벨 이름 반영\n",
        "model.config.id2label = id2label\n",
        "model.config.label2id = label2id\n",
        "\n",
        "model.to(device) #GPU로 업로드"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1b4N_zrnd7mG",
        "outputId": "fe9b00a9-189d-4ca0-9775-d4bad4e1e690"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-18 and are newly initialized because the shapes did not match:\n",
            "- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([10]) in the model instantiated\n",
            "- classifier.1.weight: found shape torch.Size([1000, 512]) in the checkpoint and torch.Size([10, 512]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNetForImageClassification(\n",
              "  (resnet): ResNetModel(\n",
              "    (embedder): ResNetEmbeddings(\n",
              "      (embedder): ResNetConvLayer(\n",
              "        (convolution): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "        (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (pooler): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (encoder): ResNetEncoder(\n",
              "      (stages): ModuleList(\n",
              "        (0): ResNetStage(\n",
              "          (layers): Sequential(\n",
              "            (0): ResNetBasicLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1): ResNetBasicLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1): ResNetStage(\n",
              "          (layers): Sequential(\n",
              "            (0): ResNetBasicLayer(\n",
              "              (shortcut): ResNetShortCut(\n",
              "                (convolution): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1): ResNetBasicLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): ResNetStage(\n",
              "          (layers): Sequential(\n",
              "            (0): ResNetBasicLayer(\n",
              "              (shortcut): ResNetShortCut(\n",
              "                (convolution): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1): ResNetBasicLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (3): ResNetStage(\n",
              "          (layers): Sequential(\n",
              "            (0): ResNetBasicLayer(\n",
              "              (shortcut): ResNetShortCut(\n",
              "                (convolution): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1): ResNetBasicLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 일부 레이어만 학습하도록, 손실함수, 옵티마이저"
      ],
      "metadata": {
        "id": "LzAdVSuGfTeZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#전체 파라미터 동결\n",
        "for p in model.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "#마지막 블록 layer4와 분류기만 학습 허용\n",
        "for p in model.resnet.encoder.stages[-1].parameters():\n",
        "    p.requires_grad = True\n",
        "for p in model.classifier.parameters():\n",
        "    p.requires_grad = True\n",
        "\n",
        "criterion = nn.CrossEntropyLoss() #크로스엔트로피 손실함수\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=0.01) #Adma 옵티마이저, 학습률 0.0001, 가중치 감쇠 : 0.001 -> 과적합 방지"
      ],
      "metadata": {
        "id": "NB4C5POsfVxJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습"
      ],
      "metadata": {
        "id": "2YSNanCygU0D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time() # 학습 시작 시간\n",
        "\n",
        "epochs = 10 #에포크 10\n",
        "\n",
        "for epoch in range(1, epochs + 1): #각 에포크마다 학습 진행\n",
        "    model.train()  #모델 학습모드로 변환\n",
        "    total, correct, loss_sum = 0, 0, 0.0 #train 이미지 수, 맞힌 개수, 손실 누적합\n",
        "    for imgs, labels in train_loader: #각 배치별로\n",
        "        imgs, labels = imgs.to(device), labels.to(device) #데이터를 GPU로 옮김\n",
        "\n",
        "        optimizer.zero_grad() #이전 배치에서의 그레디언트를 초기화\n",
        "        logits = model(pixel_values=imgs).logits #로짓 출력 결과값 얻음\n",
        "        loss = criterion(logits, labels) #손실 계산\n",
        "        loss.backward() #역전파 진행\n",
        "        optimizer.step() #계산된 그레디언트로 모델의 파라미터를 한 스텝 업데이트\n",
        "\n",
        "        loss_sum += loss.item() * labels.size(0) #이번 배치의 손실값을 누적합에 더함, lebels.size(0)는 배치의 크기\n",
        "        correct += (logits.argmax(1) == labels).sum().item() #정답을 맞춘 것의 개수\n",
        "        total += labels.size(0) #처리한 데이터의 개수 (배치 크기)\n",
        "\n",
        "    #평균 손실과 정확도 계산\n",
        "    train_loss = loss_sum / total\n",
        "    train_acc  = correct / total * 100\n",
        "\n",
        "    # validation 평가\n",
        "    # train의 결과 평가와 같은 구조\n",
        "    model.eval() #모델 평가모드로 전환\n",
        "    v_total, v_correct, v_loss_sum = 0, 0, 0.0\n",
        "    with torch.no_grad(): #평가에선 그레디언트를 사용하지 않음\n",
        "        for imgs, labels in val_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            logits = model(pixel_values=imgs).logits\n",
        "\n",
        "            v_loss_sum += criterion(logits, labels).item() * labels.size(0)\n",
        "            v_correct += (logits.argmax(1) == labels).sum().item()\n",
        "            v_total += labels.size(0)\n",
        "\n",
        "    val_loss = v_loss_sum / v_total\n",
        "    val_acc  = v_correct / v_total * 100\n",
        "    #학습, 검증 손실 및 정확도 출력\n",
        "    print(f\"[{epoch}/{epochs}] train_loss {train_loss:.4f} acc {train_acc:.2f}% | val_loss {val_loss:.4f} acc {val_acc:.2f}%\")\n",
        "\n",
        "print(\"-\"*30)\n",
        "total_time = time.time() - start_time\n",
        "print(f\"Pratial Fine Tuning 학습 소요 시간: {total_time:.2f}초\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Opi8VkXugVrR",
        "outputId": "16607594-40c3-4ee2-836c-7840bba7b473"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/10] train_loss 0.5519 acc 81.41% | val_loss 0.3335 acc 88.17%\n",
            "[2/10] train_loss 0.1954 acc 94.09% | val_loss 0.3080 acc 89.24%\n",
            "[3/10] train_loss 0.0610 acc 98.93% | val_loss 0.3066 acc 89.77%\n",
            "[4/10] train_loss 0.0185 acc 99.89% | val_loss 0.3046 acc 90.26%\n",
            "[5/10] train_loss 0.0073 acc 99.99% | val_loss 0.3099 acc 90.36%\n",
            "[6/10] train_loss 0.0039 acc 100.00% | val_loss 0.3120 acc 90.53%\n",
            "[7/10] train_loss 0.0025 acc 100.00% | val_loss 0.3196 acc 90.53%\n",
            "[8/10] train_loss 0.0020 acc 100.00% | val_loss 0.3279 acc 90.41%\n",
            "[9/10] train_loss 0.0014 acc 100.00% | val_loss 0.3310 acc 90.41%\n",
            "[10/10] train_loss 0.0011 acc 100.00% | val_loss 0.3371 acc 90.54%\n",
            "------------------------------\n",
            "Pratial Fine Tuning 학습 소요 시간: 469.51초\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 테스트 평가"
      ],
      "metadata": {
        "id": "I5b7bgLAgzy3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#validation의 경우와 같음\n",
        "model.eval()\n",
        "total, correct, loss_sum = 0, 0, 0.0\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in test_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        logits = model(pixel_values=imgs).logits\n",
        "        loss_sum += criterion(logits, labels).item() * labels.size(0)\n",
        "        correct += (logits.argmax(1) == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "test_loss = loss_sum / total\n",
        "test_acc  = correct / total * 100\n",
        "print(\"Partial Fine Tuning CIFAR-10 테스트 손실 및 정확도\")\n",
        "print(f\"test_loss {test_loss:.4f} acc {test_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8kelnzrgzeX",
        "outputId": "00acecf7-89ed-4fb4-fd2c-f29648979458"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Partial Fine Tuning CIFAR-10 테스트 손실 및 정확도\n",
            "test_loss 0.3496 acc 90.56%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# III. Progressive Fine Tuning"
      ],
      "metadata": {
        "id": "Li8mPy7NiEYv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUyPcFbv1sgR",
        "outputId": "46ccf299-504e-417c-fc37-9c42e266ab05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed fixed to 42]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "단계적 파인튜닝  \n",
        "처음엔 모델의 상위레이어만 동결 해제,  \n",
        "학습이 어느정도 안정되면  \n",
        "학습 후 일부 하위 레이어 동결해제  \n",
        "\n",
        "점진적으로 학습 범위 넓혀가기"
      ],
      "metadata": {
        "id": "v93qpkbiiJ2r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "처음부터 모든 파라미터를 학습하면  \n",
        "기존의 사전학습 가중치가 무너질 수 있음  \n",
        "특히 작은 데이터셋에선 과적합, 손실 폭주가 발생  \n",
        "\n",
        "이것은 학습량을 서서히 늘려가기 때문에 과적합 억제 가능"
      ],
      "metadata": {
        "id": "38m93l_4iZw9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ResNet-18 모델 재로드 및 출력부 헤드 설정"
      ],
      "metadata": {
        "id": "uPnpGhgBisie"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YcOl5SF019Ik",
        "outputId": "a13e76c6-96e0-46f2-99ec-dfb93bab24e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Seed fixed to 42]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForImageClassification\n",
        "\n",
        "num_labels = 10 #CIFAR-10 클래스의 개수\n",
        "model = AutoModelForImageClassification.from_pretrained(\n",
        "    \"microsoft/resnet-18\",\n",
        "    num_labels=num_labels,\n",
        "    ignore_mismatched_sizes=True  # 분류기 헤드 차원 재설정 시 편의용\n",
        ")\n",
        "\n",
        "#CIFAR-10 라벨 이름 반영\n",
        "model.config.id2label = id2label\n",
        "model.config.label2id = label2id\n",
        "\n",
        "model.to(device) #GPU로 업로드"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dh-z2YhQiJL3",
        "outputId": "1cc66c4a-9fc3-4baf-ea8b-9e7a0c7f17c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-18 and are newly initialized because the shapes did not match:\n",
            "- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([10]) in the model instantiated\n",
            "- classifier.1.weight: found shape torch.Size([1000, 512]) in the checkpoint and torch.Size([10, 512]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ResNetForImageClassification(\n",
              "  (resnet): ResNetModel(\n",
              "    (embedder): ResNetEmbeddings(\n",
              "      (embedder): ResNetConvLayer(\n",
              "        (convolution): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
              "        (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "        (activation): ReLU()\n",
              "      )\n",
              "      (pooler): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
              "    )\n",
              "    (encoder): ResNetEncoder(\n",
              "      (stages): ModuleList(\n",
              "        (0): ResNetStage(\n",
              "          (layers): Sequential(\n",
              "            (0): ResNetBasicLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1): ResNetBasicLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (1): ResNetStage(\n",
              "          (layers): Sequential(\n",
              "            (0): ResNetBasicLayer(\n",
              "              (shortcut): ResNetShortCut(\n",
              "                (convolution): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1): ResNetBasicLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (2): ResNetStage(\n",
              "          (layers): Sequential(\n",
              "            (0): ResNetBasicLayer(\n",
              "              (shortcut): ResNetShortCut(\n",
              "                (convolution): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1): ResNetBasicLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (3): ResNetStage(\n",
              "          (layers): Sequential(\n",
              "            (0): ResNetBasicLayer(\n",
              "              (shortcut): ResNetShortCut(\n",
              "                (convolution): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "              )\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "            (1): ResNetBasicLayer(\n",
              "              (shortcut): Identity()\n",
              "              (layer): Sequential(\n",
              "                (0): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): ReLU()\n",
              "                )\n",
              "                (1): ResNetConvLayer(\n",
              "                  (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (normalization): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (activation): Identity()\n",
              "                )\n",
              "              )\n",
              "              (activation): ReLU()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): AdaptiveAvgPool2d(output_size=(1, 1))\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Linear(in_features=512, out_features=10, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 점진적인 레이어 학습 설정"
      ],
      "metadata": {
        "id": "t2l06hp7i7Pu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모든 레이어 동결\n",
        "for p in model.parameters():\n",
        "    p.requires_grad = False\n",
        "\n",
        "# 분류기만 학습 허용\n",
        "for p in model.classifier.parameters():\n",
        "    p.requires_grad = True"
      ],
      "metadata": {
        "id": "82iLxjI4i9UA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 손실함수, 옵티마이저 재구성"
      ],
      "metadata": {
        "id": "CVgwldwfjfx1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#단계적 학습을 진행하기 때문에 옵티마이저를 변환하여야 한다\n",
        "#왜냐하면 새로 파라미터가 열리면 옵티마이저를 새로 생성해야 하기 때문이다\n",
        "def build_optimizer():\n",
        "    \"\"\"현재 requires_grad=True인 파라미터를 기준으로 param group 구성\"\"\"\n",
        "    #학습 가능한 파라미터\n",
        "    head_params = [p for n,p in model.named_parameters() if p.requires_grad and n.startswith(\"classifier\")]\n",
        "    #학습 불가능한 파라미터 (사전 학습된 본체)\n",
        "    bb_params   = [p for n,p in model.named_parameters() if p.requires_grad and not n.startswith(\"classifier\")]\n",
        "    param_groups = []\n",
        "    if head_params: param_groups.append({\"params\": head_params, \"lr\": 1e-3}) #학습해야 하는건 빠르게\n",
        "    if bb_params:   param_groups.append({\"params\": bb_params, \"lr\": 1e-4}) #사전 학습된 본체는 느리게\n",
        "    return torch.optim.AdamW(param_groups, weight_decay=0.01)\n",
        "\n",
        "optimizer = build_optimizer()"
      ],
      "metadata": {
        "id": "e9sdVSmKjiNB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 단계적 동결 해제"
      ],
      "metadata": {
        "id": "fCelCsszjlgh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stages = model.resnet.encoder.stages #모든 레이어 호출\n",
        "def unfreeze_stage(idx: int):\n",
        "    \"\"\"\n",
        "    4번째 레이어 : idx = -1\n",
        "    3번째 레이어 : idx = -2\n",
        "    2번째 레이어 : idx = -3\n",
        "\n",
        "    후에 각 에포크별로 동결 해제 할 레이어를 idx로 지정\n",
        "    \"\"\"\n",
        "    for p in stages[idx].parameters():\n",
        "        p.requires_grad = True\n",
        "\n",
        "def reinit_optimizer():\n",
        "    \"\"\"\n",
        "    동결 해제 후 옵티마이저 재구성\n",
        "    \"\"\"\n",
        "    global optimizer\n",
        "    optimizer = build_optimizer()"
      ],
      "metadata": {
        "id": "BNPgbI47jm0X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 학습"
      ],
      "metadata": {
        "id": "U6p07H84kg7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "start_time = time.time() # 학습 시작 시간\n",
        "\n",
        "epochs = 10\n",
        "unfreeze_schedule = {4: -1, 7: -2}  # 에포크 4에서 4번째 레이어, 에포크 7에서 3번째 레이어 동결해제\n",
        "\n",
        "for epoch in range(1, epochs + 1): #각 에포크마다 학습 진행\n",
        "\n",
        "    #에포크에 맞추어 레이어 동결해제\n",
        "    if epoch in unfreeze_schedule:\n",
        "        unfreeze_stage(unfreeze_schedule[epoch]) #동결 해제\n",
        "        reinit_optimizer() #옵티마이저 재구성\n",
        "\n",
        "    model.train()  #모델 학습모드로 변환\n",
        "    total, correct, loss_sum = 0, 0, 0.0 #train 이미지 수, 맞힌 개수, 손실 누적합\n",
        "    for imgs, labels in train_loader: #각 배치별로\n",
        "        imgs, labels = imgs.to(device), labels.to(device) #데이터를 GPU로 옮김\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True) #이전 배치에서의 그레디언트를 초기화\n",
        "        logits = model(pixel_values=imgs).logits #로짓 출력 결과값 얻음\n",
        "        loss = criterion(logits, labels) #손실 계산\n",
        "        loss.backward() #역전파 진행\n",
        "        optimizer.step() #계산된 그레디언트로 모델의 파라미터를 한 스텝 업데이트\n",
        "\n",
        "        loss_sum += loss.item() * labels.size(0) #이번 배치의 손실값을 누적합에 더함, lebels.size(0)는 배치의 크기\n",
        "        correct += (logits.argmax(1) == labels).sum().item() #정답을 맞춘 것의 개수\n",
        "        total += labels.size(0) #처리한 데이터의 개수 (배치 크기)\n",
        "\n",
        "    #평균 손실과 정확도 계산\n",
        "    train_loss = loss_sum / total\n",
        "    train_acc  = correct / total * 100\n",
        "\n",
        "    # validation 평가\n",
        "    # train의 결과 평가와 같은 구조\n",
        "    model.eval() #모델 평가모드로 전환\n",
        "    v_total, v_correct, v_loss_sum = 0, 0, 0.0\n",
        "    with torch.no_grad(): #평가에선 그레디언트를 사용하지 않음\n",
        "        for imgs, labels in val_loader:\n",
        "            imgs, labels = imgs.to(device), labels.to(device)\n",
        "            logits = model(pixel_values=imgs).logits\n",
        "\n",
        "            v_loss_sum += criterion(logits, labels).item() * labels.size(0)\n",
        "            v_correct += (logits.argmax(1) == labels).sum().item()\n",
        "            v_total += labels.size(0)\n",
        "\n",
        "    val_loss = v_loss_sum / v_total\n",
        "    val_acc  = v_correct / v_total * 100\n",
        "    #학습, 검증 손실 및 정확도 출력\n",
        "    print(f\"[{epoch}/{epochs}] train_loss {train_loss:.4f} acc {train_acc:.2f}% | val_loss {val_loss:.4f} acc {val_acc:.2f}%\")\n",
        "\n",
        "print(\"-\"*30)\n",
        "total_time = time.time() - start_time\n",
        "print(f\"Progressive Fine Tuning 학습 소요 시간: {total_time:.2f}초\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDTOHD-2kG9L",
        "outputId": "f53f8e71-067e-4bc6-eb41-23e80861d436"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1/10] train_loss 1.0468 acc 66.95% | val_loss 0.7626 acc 74.28%\n",
            "[2/10] train_loss 0.7277 acc 75.51% | val_loss 0.6931 acc 76.21%\n",
            "[3/10] train_loss 0.6772 acc 76.96% | val_loss 0.6617 acc 76.99%\n",
            "[4/10] train_loss 0.4389 acc 84.82% | val_loss 0.3283 acc 88.45%\n",
            "[5/10] train_loss 0.1284 acc 96.02% | val_loss 0.3371 acc 88.71%\n",
            "[6/10] train_loss 0.0333 acc 99.28% | val_loss 0.3443 acc 89.60%\n",
            "[7/10] train_loss 0.0646 acc 97.76% | val_loss 0.4448 acc 88.34%\n",
            "[8/10] train_loss 0.0367 acc 98.77% | val_loss 0.4435 acc 89.36%\n",
            "[9/10] train_loss 0.0220 acc 99.22% | val_loss 0.4309 acc 89.84%\n",
            "[10/10] train_loss 0.0255 acc 99.13% | val_loss 0.5117 acc 88.87%\n",
            "------------------------------\n",
            "Progressive Fine Tuning 학습 소요 시간: 467.95초\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 테스트 평가"
      ],
      "metadata": {
        "id": "wv8dIEOTmvK1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#validation의 경우와 같음\n",
        "model.eval()\n",
        "total, correct, loss_sum = 0, 0, 0.0\n",
        "with torch.no_grad():\n",
        "    for imgs, labels in test_loader:\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        logits = model(pixel_values=imgs).logits\n",
        "        loss_sum += criterion(logits, labels).item() * labels.size(0)\n",
        "        correct += (logits.argmax(1) == labels).sum().item()\n",
        "        total += labels.size(0)\n",
        "\n",
        "test_loss = loss_sum / total\n",
        "test_acc  = correct / total * 100\n",
        "print(\"Progressive Fine Tuning CIFAR-10 테스트 손실 및 정확도\")\n",
        "print(f\"test_loss {test_loss:.4f} acc {test_acc:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d06acol_mn7C",
        "outputId": "d83030ed-fac0-48ad-a0ee-89ecd9f4a2ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Progressive Fine Tuning CIFAR-10 테스트 손실 및 정확도\n",
            "test_loss 0.5359 acc 88.88%\n"
          ]
        }
      ]
    }
  ]
}
